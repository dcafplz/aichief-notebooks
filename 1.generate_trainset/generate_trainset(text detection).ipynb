{"cells":[{"cell_type":"markdown","source":["### onedrive내 train data를 가공해 yolov5 trainset을 만들기 위한 notebook\n","  - input: 다양한 size의 image, x, y, w, h정보 label\n","  - output: 손글씨 형태만 crop된 이미지"],"metadata":{"id":"xamGeM4GxF0D"}},{"cell_type":"markdown","metadata":{"id":"-GP93gzgpJSW"},"source":["### onedrive & google drive mount"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_G3LGh_a0vz"},"outputs":[],"source":["!wget https://downloads.rclone.org/v1.57.0/rclone-v1.57.0-linux-amd64.deb\n","!apt install ./rclone-v1.57.0-linux-amd64.deb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtdVRESKbPIi"},"outputs":[],"source":["!rclone config"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1666833068986,"user":{"displayName":"ᄆᄆ","userId":"04446057954788773347"},"user_tz":-540},"id":"SkPAElt0bI6U","outputId":"0ef47492-2413-4a34-9b11-5c828e64ca2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["nohup: appending output to 'nohup.out'\n"]}],"source":["!mkdir onedrive\n","!nohup rclone --vfs-cache-mode writes mount onedrive: ./onedrive &    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20232,"status":"ok","timestamp":1666833089547,"user":{"displayName":"ᄆᄆ","userId":"04446057954788773347"},"user_tz":-540},"id":"87XD9H6dY9o0","outputId":"30a0485d-7367-45ed-ad06-15cf2bd3d4c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"8ZRsLClwp8V2"},"source":["### generate"]},{"cell_type":"code","source":["import zipfile\n","import cv2\n","import numpy as np\n","import os\n","import shutil\n","import json\n","import matplotlib.pyplot as plt\n","import random"],"metadata":{"id":"HwJi5B7c3xWV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cnt = 0"],"metadata":{"id":"ZaG55GJSathT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7l_26zc9RFu"},"outputs":[],"source":["source_file = r'/content/onedrive/playdata/final_project/financial/train/financial_ocr_ts2.zip'\n","ann_file = r'/content/onedrive/playdata/final_project/financial/train/financial_ocr_tl2.zip'\n","\n","with zipfile.ZipFile(source_file, 'r') as zf:\n","\tzf.extractall('/content')\n","\n","with zipfile.ZipFile(ann_file, 'r') as zf:\n","\tzf.extractall('/content')"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","train, val = train_test_split(os.listdir(r'/content/result/insure/annotations'), test_size=0.2)\n","cnt = 0\n","train_list = []\n","val_list = []"],"metadata":{"id":"bAKQCjEm4LJ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"09Qq20JIxCks"},"outputs":[],"source":["with zipfile.ZipFile(r'/content/drive/MyDrive/final_project/train.zip', 'w', compression=zipfile.ZIP_DEFLATED) as new_zip:\n","  for j in train:\n","    with open(f'/content/result/insure/annotations/{j}', encoding='UTF8') as f:\n","      json_object = json.load(f)\n","    cnt += 1\n","    img = cv2.imread(f'/content/result/insure/images/{json_object[\"name\"]}', cv2.IMREAD_GRAYSCALE)\n","    x_size, y_size = img.shape[1], img.shape[0]\n","    path_img = f'{str(cnt).zfill(5)}.jpg'\n","    path_txt = f'{str(cnt).zfill(5)}.txt'\n","    cv2.imwrite(path_img, cv2.resize(img[:x_size], (640, 640), interpolation=cv2.INTER_AREA))\n","    with open(path_txt, 'w') as w:\n","      for dic in json_object['annotations'][0]['bbox']:\n","          x, y, width, height = int(dic['x']), int(dic['y']), int(dic['width']), int(dic['height'])\n","          print(x, y, width, height)\n","          if y+height < x_size:\n","            print(f'{0} {((x+x+width)/2)/x_size:4f} {((y+y+height)/2)/x_size:4f} {width/x_size:4f} {height/x_size:4f}\\n')\n","            w.write(f'{0} {((x+x+width)/2)/x_size:4f} {((y+y+height)/2)/x_size:4f} {width/x_size:4f} {height/x_size:4f}\\n')\n","    new_zip.write(path_txt)\n","    new_zip.write(path_img)\n","    train_list.append(path_img)\n","    os.remove(path_img)\n","    os.remove(path_txt)\n","\n","with open('/content/drive/MyDrive/final_project/train.txt', 'w') as w:\n","  w.write('\\n'.join(train_list))"]},{"cell_type":"code","source":["with zipfile.ZipFile(r'/content/drive/MyDrive/final_project/val.zip', 'w', compression=zipfile.ZIP_DEFLATED) as new_zip:\n","  for j in val:\n","    with open(f'/content/result/insure/annotations/{j}', encoding='UTF8') as f:\n","      json_object = json.load(f)\n","    cnt += 1\n","    img = cv2.imread(f'/content/result/insure/images/{json_object[\"name\"]}', cv2.IMREAD_GRAYSCALE)\n","    x_size, y_size = img.shape[1], img.shape[0]\n","    path_img = f'{str(cnt).zfill(5)}.jpg'\n","    path_txt = f'{str(cnt).zfill(5)}.txt'\n","    cv2.imwrite(path_img, cv2.resize(img[:x_size], (640, 640), interpolation=cv2.INTER_AREA))\n","    with open(path_txt, 'w') as w:\n","      for dic in json_object['annotations'][0]['bbox']:\n","          x, y, width, height = int(dic['x']), int(dic['y']), int(dic['width']), int(dic['height'])\n","          if y+height < x_size:\n","            w.write(f'{0} {((x+width)/2)/x_size:4f} {((y+height)/2)/x_size:4f} {width/x_size:4f} {height/x_size:4f}\\n')\n","    new_zip.write(path_txt)\n","    new_zip.write(path_img)\n","    os.remove(path_img)\n","    os.remove(path_txt)\n","\n","with open('/content/drive/MyDrive/final_project/val.txt', 'w') as w:\n","  w.write('\\n'.join(val_list))"],"metadata":{"id":"soqrzU9184Vt"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1xnIrhTEcKkeMhJ8rtflk1XI8f24hzkxq","timestamp":1666405031390}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}